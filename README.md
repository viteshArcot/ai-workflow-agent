AI Workflow Agent  ğŸš€

A production-ready AI workflow orchestration system that combines LLM-powered task generation, ML-based prioritization, and full-stack dashboards for insights.

âœ¨ Overview

The AI Workflow Agent  is a complete end-to-end orchestration platform. It intelligently processes natural language tasks, prioritizes them with machine learning, generates context-aware subtasks using an LLM, and stores results with full history and metrics tracking.

Built with a FastAPI backend and a React + Tailwind frontend, it delivers enterprise-grade features in a clean, modern UI with dashboards for monitoring system performance.

ğŸ¯ Key Features

Custom DAG Execution â†’ Runs multi-node workflows with topological ordering.

ML-Powered Prioritization â†’ DecisionTreeClassifier trained on labeled examples to classify tasks as urgent/normal.

LLM Integration â†’ OpenRouter (Mistral-7B) for task generation and summarization.

Knowledge Base Ingestion â†’ Supports CSV/JSON ingestion for contextual task enrichment.

Execution History â†’ Queryable API with advanced filtering (priority, limits).

Metrics Dashboard â†’ Track per-node latency and accuracy trends.

Modern Frontend â†’ React + Tailwind + Recharts with smooth animations and responsive design.

ğŸ› ï¸ Tech Stack

Backend: FastAPI, scikit-learn, pandas, SQLite, OpenRouter API
Frontend: React, TailwindCSS, Framer Motion, Recharts, Axios
Architecture: Custom DAG orchestration, modular service design, REST APIs

ğŸ“Š System Architecture

Task Prioritizer â†’ ML classifier assigns urgency.

Task Generator â†’ LLM expands input into subtasks.

Summarizer â†’ LLM produces executive summaries.

Logger â†’ SQLite database stores full history + metrics.

ğŸš€ How It Works

User submits a natural language query.

System routes it through ML + LLM pipeline.

Workflow executes across nodes with tracked latency + accuracy.

Results are displayed in a dashboard (real-time updates).

ğŸ“ Project Structure
ai-workflow-agent/
â”œâ”€â”€ app/                  # FastAPI backend
â”‚   â”œâ”€â”€ main.py           # Entry point
â”‚   â”œâ”€â”€ graph.py          # DAG runner
â”‚   â”œâ”€â”€ prioritizer.py    # ML classifier
â”‚   â”œâ”€â”€ generator.py      # LLM task generator
â”‚   â”œâ”€â”€ summarizer.py     # LLM summarizer
â”‚   â”œâ”€â”€ logger.py         # Database logger
â”‚   â”œâ”€â”€ ingestion.py      # Knowledge ingestion
â”‚   â””â”€â”€ llm_client.py     # OpenRouter client
â”œâ”€â”€ frontend/             # React frontend
â”‚   â”œâ”€â”€ src/components/   # Reusable components
â”‚   â”œâ”€â”€ src/pages/        # Dashboard, History, Metrics
â”‚   â””â”€â”€ App.jsx           # Main entry
â””â”€â”€ data/                 # Training datasets

ğŸ–¼ï¸ Screenshots

(Add after running the frontend â€” History Dashboard, Metrics Charts, Workflow Execution)

ğŸ¨ Why This Project Matters

This project demonstrates applied AI engineering across multiple layers:

Backend intelligence (ML + LLM integration).

Workflow orchestration (custom DAG execution).

Full-stack delivery (React dashboards with animations).

Production quality (error handling, async, modular design).

It mirrors the real-world systems used in enterprise AI orchestration platforms.

ğŸ§‘â€ğŸ’» Setup Instructions
Backend
cd app
pip install -r requirements.txt
uvicorn app.main:app --reload

Frontend
cd frontend
npm install
npm run dev


Access app at: http://localhost:3000
